models:
  lin_reg:
    exclude_features: ["DepDel15"]
    target: "DepDelayMinutes"

  sgd_reg:
    exclude_features: ["DepDel15"]
    target: "DepDelayMinutes"
    params:
      random_state: 42
      max_iter: 5000
      learning_rate: 'optimal'
      eta0: 0.01
      alpha: 0.1
    n_iter: 50
    param_dist:
      loss: ["squared_error", "squared_epsilon_insensitive"]
      alpha: [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0]
      max_iter: [1000, 2000, 5000, 10000]
      eta0: [0.0001, 0.001, 0.01, 0.1, 1.0]
      learning_rate: ["constant", "optimal", "invscaling", "adaptive"]
      penalty: ["l2", "l1", "elasticnet"]
      random_state: [42]

  hgb_reg:
    exclude_features: ["DepDel15"]
    target: "DepDelayMinutes"
    params:
      random_state: 42
      min_samples_leaf: 5
      learning_rate: 0.1
      max_depth: 10
    n_iter: 50
    param_dist:
      learning_rate: [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]
      max_depth: [3, 5, 10, 15, None]
      min_samples_leaf: [1, 3, 5, 10, 20]
      max_iter: [100, 200, 500, 1000]
      l2_regularization: [0.0, 0.1, 0.5, 1.0]
      max_bins: [63, 127, 255]
      random_state: [42]

  mlp_reg:
    exclude_features: ["DepDel15"]
    target: "DepDelayMinutes"
    params:
      random_state: 42
    n_iter: 50
    param_dist:
      hidden_layer_sizes: [(50,), (100,), (50, 50), (100, 50), (100, 100)]
      activation: ["relu", "tanh", "logistic"]
      solver: ["adam", "sgd", "lbfgs"]
      alpha: [0.0001, 0.001, 0.01, 0.1, 1.0]
      learning_rate: ["constant", "adaptive"]
      max_iter: [500, 1000, 2000, 5000]
      random_state: [42]

  log_reg:
    exclude_features: ["DepDelayMinutes"]
    target: "DepDel15"
    params:
      solver: "saga"
      random_state: 42
    n_iter: 10
    param_dist:
      solver: ["saga"]
      random_state: [42]

  hgb_clf:
    exclude_features: ["DepDelayMinutes"]
    target: "DepDel15"
    params:
      random_state: 42
      learning_rate: 0.2
      min_samples_leaf: 1
      max_depth: 5
    n_iter: 50
    param_dist:
    param_dist:
      learning_rate: [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]
      max_depth: [3, 5, 10, 15, None]
      min_samples_leaf: [1, 3, 5, 10, 20]
      max_iter: [100, 200, 500, 1000]
      l2_regularization: [0.0, 0.1, 0.5, 1.0]
      max_bins: [63, 127, 255]
      random_state: [42]

  sgd_clf:
    exclude_features: ["DepDelayMinutes"]
    target: "DepDel15"
    params:
      random_state: 42
      max_iter: 5000
      loss: 'modified_huber'
      alpha: 0.1
    n_iter: 50
    param_dist:
      loss: ["hinge", "log_loss", "modified_huber", "squared_hinge", "perceptron"]
      alpha: [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0]
      max_iter: [1000, 2000, 5000, 10000]
      penalty: ["l2", "elasticnet"]
      random_state: [42]

  mlp_clf:
    exclude_features: ["DepDelayMinutes"]
    target: "DepDel15"
    params:
      random_state: 42
    n_iter: 50
    param_dist:
      hidden_layer_sizes: [(50,), (100,), (50, 50), (100, 50), (100, 100)]
      activation: ["relu", "tanh", "logistic"]
      solver: ["adam", "sgd", "lbfgs"]
      alpha: [0.0001, 0.001, 0.01, 0.1, 1.0]
      learning_rate: ["constant", "adaptive"]
      max_iter: [500, 1000, 2000, 5000]
      random_state: [42]
