models:
  lin_reg:
    type: "reg"
    exclude_features: ["DepDel15"]
    target: "DepDelayMinutes"

  hgb_reg:
    type: "reg"
    exclude_features: ["DepDel15"]
    target: "DepDelayMinutes"
    params:
      random_state: 42
      min_samples_leaf: 20
      max_iter: 1000
      max_depth: 10
      max_bins: 255
      learning_rate: 0.05
      l2_regularization: 0.1
    n_iter: 40
    param_dist:
      learning_rate: [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]
      max_depth: [3, 5, 10, 15]
      min_samples_leaf: [1, 3, 5, 10, 20]
      max_iter: [100, 200, 500, 1000]
      l2_regularization: [0.0, 0.1, 0.5, 1.0]
      max_bins: [63, 127, 255]
      random_state: [42]

  sgd_reg:
    type: "reg"
    exclude_features: ["DepDel15"]
    target: "DepDelayMinutes"
    params:
      random_state: 42
      penalty: 'l2'
      max_iter: 1000
      loss: 'squared_error'
      learning_rate: 'adaptive'
      eta0: 0.001
      alpha: 0.001
    n_iter: 30
    param_dist:
      loss: ["squared_error", "squared_epsilon_insensitive"]
      alpha: [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0]
      max_iter: [1000, 2000, 5000, 10000]
      eta0: [0.0001, 0.001, 0.01, 0.1, 1.0]
      learning_rate: ["constant", "optimal", "invscaling", "adaptive"]
      penalty: ["l2", "l1", "elasticnet"]
      random_state: [42]

  mlp_reg:
    type: "reg"
    exclude_features: ["DepDel15"]
    target: "DepDelayMinutes"
    params:
      random_state: 42
      solver: 'adam'
      max_iter: 1000
      learning_rate: 'adaptive'
      hidden_layer_sizes: [100]
      alpha: 1.0
      activation: 'logistic'
    n_iter: 20
    param_dist:
      hidden_layer_sizes:
        - [50]
        - [100]
        - [50, 50]
        - [100, 50]
        - [100, 100]
      activation: ["relu", "tanh", "logistic"]
      solver: ["adam", "sgd", "lbfgs"]
      alpha: [0.0001, 0.001, 0.01, 0.1, 1.0]
      learning_rate: ["constant", "adaptive"]
      max_iter: [500, 1000, 2000, 5000]
      random_state: [42]

  log_reg:
    type: "clf"
    exclude_features: ["DepDelayMinutes"]
    target: "DepDel15"
    params:
      solver: "saga"
      random_state: 42
    n_iter: 10
    param_dist:
      solver: ["saga"]
      random_state: [42]

  hgb_clf:
    type: "clf"
    exclude_features: ["DepDelayMinutes"]
    target: "DepDel15"
    params:
      random_state: 42
      min_samples_leaf: 3
      max_iter: 500
      max_depth: 10
      max_bins: 63
      learning_rate: 0.05
      l2_regularization: 0.5
    n_iter: 40
    param_dist:
      learning_rate: [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]
      max_depth: [3, 5, 10, 15]
      min_samples_leaf: [1, 3, 5, 10, 20]
      max_iter: [100, 200, 500, 1000]
      l2_regularization: [0.0, 0.1, 0.5, 1.0]
      max_bins: [63, 127, 255]
      random_state: [42]

  sgd_clf:
    type: "clf"
    exclude_features: ["DepDelayMinutes"]
    target: "DepDel15"
    params:
      random_state: 42
      penalty: 'elasticnet'
      max_iter: 5000
      loss: 'log_loss'
      alpha: 0.001
    n_iter: 30
    param_dist:
      loss: ["hinge", "log_loss", "modified_huber", "squared_hinge", "perceptron"]
      alpha: [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0]
      max_iter: [1000, 2000, 5000, 10000]
      penalty: ["l2", "elasticnet"]
      random_state: [42]

  mlp_clf:
    type: "clf"
    exclude_features: ["DepDelayMinutes"]
    target: "DepDel15"
    params:
      random_state: 42
      solver: 'sgd'
      max_iter: 2000
      learning_rate: 'constant'
      hidden_layer_sizes: [100, 100]
      alpha: 0.01
      activation: 'tanh'
    n_iter: 20
    param_dist:
      hidden_layer_sizes:
        - [50]
        - [100]
        - [50, 50]
        - [100, 50]
        - [100, 100]
      activation: ["relu", "tanh", "logistic"]
      solver: ["adam", "sgd", "lbfgs"]
      alpha: [0.0001, 0.001, 0.01, 0.1, 1.0]
      learning_rate: ["constant", "adaptive"]
      max_iter: [500, 1000, 2000, 5000]
      random_state: [42]
