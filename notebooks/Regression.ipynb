{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "df_test = pd.read_csv(\"data/fina/test_data.csv\")\n",
    "\n",
    "# Drop classification target to avoid leakage\n",
    "df_test = df_test.drop(columns=['DepDelay'])\n",
    "\n",
    "# Extract features and target\n",
    "X_test = df_test.drop(columns=['DepDelayMinutes'])\n",
    "y_test = df_test['DepDelayMinutes'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression models\n",
    "regression_models = {\n",
    "    \"Linear Regression\": \"models/linear_regression/linear_regression.pkl\",\n",
    "    \"SGD Regression\": \"models/sgd_regressor/sgd_regressor.pkl\",\n",
    "    \"HistGradient Regression\": \"models/histgradient_regression/histgradientboosting_regression.pkl\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for results\n",
    "regression_results = []\n",
    "model_predictions = {}\n",
    "\n",
    "# Load models and evaluate\n",
    "for model_name, file in regression_models.items():\n",
    "    with open(file, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    model_predictions[model_name] = y_pred\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    regression_results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"RÂ²\": r2\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "df_regression = pd.DataFrame(regression_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualization ---\n",
    "\n",
    "# 1. Regression Performance Bar Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_regression.set_index(\"Model\").plot(kind=\"bar\", figsize=(10, 6))\n",
    "plt.title(\"Regression Model Performance Comparison\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 2. Residual Plots\n",
    "for model_name in regression_models.keys():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(y_test - model_predictions[model_name], bins=30, kde=True)\n",
    "    plt.title(f\"Residual Distribution - {model_name}\")\n",
    "    plt.xlabel(\"Residuals\")\n",
    "    plt.show()\n",
    "\n",
    "# 3. Actual vs Predicted Scatter Plot\n",
    "for model_name in regression_models.keys():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_test, model_predictions[model_name], alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color=\"red\", linestyle=\"--\")\n",
    "    plt.title(f\"Actual vs. Predicted - {model_name}\")\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
